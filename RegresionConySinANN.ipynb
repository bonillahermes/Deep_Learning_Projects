{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonillahermes/Deep_Learning_Projects/blob/main/RegresionConySinANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hermes Yate Bonilla\n",
        "**Data Scientist**\n",
        "---\n",
        "\n",
        "**Contact:**\n",
        "- **Email:** [bonillahermes@gmail.com](mailto:bonillahermes@gmail.com)\n",
        "- **LinkedIn:** [linkedin.com/in/bonillahermes](https://www.linkedin.com/in/bonillahermes/)\n",
        "- **GitHub:** [github.com/bonillahermes](https://github.com/bonillahermes)\n",
        "- **Webpage:** [bonillahermes.com](https://bonillahermes.com/)\n",
        "---"
      ],
      "metadata": {
        "id": "gc8s1cS7MJkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Regresión con y Sin ANN"
      ],
      "metadata": {
        "id": "UwQx6p3EMLK7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apartado A"
      ],
      "metadata": {
        "id": "dONZaW6VOt3R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descripción del Conjunto de Datos\n",
        "\n",
        "El conjunto de datos utilizado en este análisis proviene de un archivo público sobre costos de seguros. Incluye información demográfica, hábitos y datos geográficos de los asegurados, junto con los cargos de seguro incurridos. Las variables específicas son:\n",
        "\n",
        "- `Edad`: Edad del asegurado.\n",
        "- `Sexo`: Género del asegurado (masculino o femenino).\n",
        "- `BMI`: Índice de masa corporal, que proporciona una comprensión del cuerpo, pesos que son relativamente altos o bajos en relación con la altura, índice objetivo de peso corporal (kg/m^2).\n",
        "- `Hijos`: Número de hijos/dependientes cubiertos por el seguro de salud.\n",
        "- `Fumador`: Indica si el asegurado fuma o no.\n",
        "- `Región`: El área residencial del asegurado en los EE. UU., dividida en cuatro regiones geográficas: noreste, sureste, suroeste, noroeste.\n",
        "- `Cargos`: Costos médicos individuales facturados por el seguro de salud.\n",
        "\n",
        "## Problema de Regresión\n",
        "\n",
        "El objetivo principal de este análisis es predecir los `Cargos` de seguro de salud de un individuo, que es una variable continua, basándonos en las características demográficas y de comportamiento del asegurado. Este es un problema típico de regresión, donde se intenta estimar una variable de salida continua a partir de múltiples variables de entrada.\n",
        "\n",
        "### Metodología\n",
        "\n",
        "Para resolver este problema de regresión, se implementarán y compararán dos enfoques principales:\n",
        "\n",
        "1. **Regresión con Modelos Tradicionales**: Se utilizarán métodos de regresión no basados en redes neuronales como regresión lineal o regresión forestal aleatoria para establecer una línea base de predicción.\n",
        "\n",
        "2. **Redes Neuronales con TensorFlow**: Se empleará una red neuronal artificial utilizando TensorFlow, una biblioteca de aprendizaje profundo. Esta red será configurada y entrenada para predecir los cargos del seguro a partir de las variables de entrada. Se explorarán distintas arquitecturas de red para determinar la configuración más efectiva.\n",
        "\n",
        "El rendimiento de los modelos se evaluará y comparará utilizando métricas adecuadas, como el Error Cuadrático Medio (MSE), para determinar la precisión de las predicciones en los datos de prueba. La elección del modelo final se basará tanto en la precisión de la predicción como en la comprensión de las características subyacentes que más influyen en los cargos del seguro.\n"
      ],
      "metadata": {
        "id": "Hyhuc4DiUssq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaciones de bibliotecas estándar\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "\n",
        "# Importaciones de bibliotecas de terceros\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Importaciones de scikit-learn para preprocesamiento, modelado y evaluación\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Imprimir la versión de TensorFlow\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "id": "k02k53vsNLZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos\n",
        "url = \"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "vazZKxNDNOhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TghwyZhHSgAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "RswEJ0CKSlze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir las variables 'sex' y 'smoker' a valores binarios (0 y 1)\n",
        "df['sex'] = df['sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
        "df['smoker'] = df['smoker'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "\n",
        "# Convertir la variable 'region' a formato one-hot\n",
        "df = pd.get_dummies(df, columns=['region'])\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame para verificar los cambios\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "rLtZsdIDcSvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df.sample(frac=0.8,random_state=0)\n",
        "test_df = df.drop(train_df.index)"
      ],
      "metadata": {
        "id": "6-zhXY2DTEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_stats = train_df.describe()\n",
        "train_stats.pop(\"charges\")\n",
        "train_df.columns\n"
      ],
      "metadata": {
        "id": "qW-1nZU-VZTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "metadata": {
        "id": "XU0t4_DzrEO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(train_df[[\"age\", \"bmi\", \"children\", \"charges\"]], diag_kind=\"kde\")"
      ],
      "metadata": {
        "id": "gnnOf6flTM77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de Regresión con Redes Neuronales"
      ],
      "metadata": {
        "id": "LJkidmxHPymt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train_df.pop('charges')\n",
        "test_labels = test_df.pop('charges')\n",
        "\n",
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "normed_train_data = norm(train_df)\n",
        "normed_test_data = norm(test_df)"
      ],
      "metadata": {
        "id": "5Hc7kSFcW9QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_improved_model(input_shape):\n",
        "    model = Sequential()\n",
        "    # Añadir normalización por lotes\n",
        "    model.add(BatchNormalization(input_shape=[input_shape]))\n",
        "    # Añadir capas densas con regularización L2 y dropout para reducir el sobreajuste\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Utilizar Adam como optimizador con una tasa de aprendizaje reducida\n",
        "    optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(loss='mse',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['mae', 'mse'])\n",
        "    return model\n",
        "\n",
        "# Construir el modelo mejorado\n",
        "improved_model = build_improved_model(input_shape=len(train_df.keys()))\n",
        "\n",
        "\n",
        "# Implementar parada temprana\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "# Entrenar el modelo con la parada temprana\n",
        "history = improved_model.fit(normed_train_data, train_labels,\n",
        "                             epochs=EPOCHS, validation_split=0.2, verbose=0,\n",
        "                             callbacks=[early_stop])\n",
        "\n"
      ],
      "metadata": {
        "id": "ReLi1qVuNRkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "improved_model.summary()"
      ],
      "metadata": {
        "id": "_WgsU_XEYc6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "metadata": {
        "id": "mXs7_Dvhf_6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history):\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    hist['epoch'] = history.epoch\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Abs Error [charges]')\n",
        "    # Comprobamos si los datos están presentes antes de graficar\n",
        "    if 'mae' in hist and 'val_mae' in hist:\n",
        "        plt.plot(hist['epoch'], hist['mae'], label='Train Error')\n",
        "        plt.plot(hist['epoch'], hist['val_mae'], label='Val Error')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Mean Square Error [$charges^2$]')\n",
        "    # Comprobamos si los datos están presentes antes de graficar\n",
        "    if 'mse' in hist and 'val_mse' in hist:\n",
        "        plt.plot(hist['epoch'], hist['mse'], label='Train Error')\n",
        "        plt.plot(hist['epoch'], hist['val_mse'], label='Val Error')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n"
      ],
      "metadata": {
        "id": "5ywNYqYjgJs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae, mse = improved_model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} charges\".format(mae))"
      ],
      "metadata": {
        "id": "B6sNMv_d1FC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae, mse = improved_model.evaluate(normed_train_data, train_labels, verbose=2)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} charges\".format(mae))"
      ],
      "metadata": {
        "id": "qR0WUexJBNoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = improved_model.predict(normed_test_data).flatten()\n",
        "\n",
        "# test_labels contiene los valores reales\n",
        "# test_predictions contiene los valores predichos por el modelo\n",
        "\n",
        "# Gráfico de dispersión de las etiquetas verdaderas vs predicciones\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "\n",
        "# Etiquetas de los ejes\n",
        "plt.xlabel('True Values [charges]')\n",
        "plt.ylabel('Predictions [charges]')\n",
        "\n",
        "# Establecer un aspecto de eje igual y cuadrado para la gráfica\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "\n",
        "# Establecer los límites de los ejes para tener el mismo rango\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "\n",
        "# Dibujar una línea y=x para referencia\n",
        "plt.plot([-100, 100], [-100, 100])\n",
        "\n",
        "# Ajustar un modelo lineal a los datos para obtener la línea de tendencia\n",
        "z = np.polyfit(test_labels, test_predictions, 1)\n",
        "p = np.poly1d(z)\n",
        "\n",
        "# Dibujar la línea de tendencia\n",
        "plt.plot(test_labels, p(test_labels), \"r--\")\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5tzReIB51_OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [charges]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "metadata": {
        "id": "xxh-Mytq2LJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de regresión sin Usar Redes Neuronales"
      ],
      "metadata": {
        "id": "5llUnTME7GjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('charges', axis=1)  # Elimina la columna 'charges' y usa el resto como características\n",
        "y = df['charges']  # Usa la columna 'charges' como la variable objetivo\n",
        "\n",
        "# Crear características polinómicas\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo de regresión Ridge\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de entrenamiento y prueba\n",
        "train_predictions = ridge_model.predict(X_train)\n",
        "test_predictions = ridge_model.predict(X_test)\n",
        "\n",
        "# Evaluar el modelo usando validación cruzada\n",
        "scores = cross_val_score(ridge_model, X_poly, y, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Calcular el error para el conjunto de entrenamiento y prueba\n",
        "train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "\n",
        "# Imprimir errores y puntuación de validación cruzada\n",
        "print(f'Train MAE: {train_mae}')\n",
        "print(f'Train MSE: {train_mse}')\n",
        "print(f'Test MAE: {test_mae}')\n",
        "print(f'Test MSE: {test_mse}')\n",
        "print(f'Cross-Validation MSE: {-scores.mean()}')\n"
      ],
      "metadata": {
        "id": "rS-nZwWo7FbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular los residuos (diferencia entre la predicción y el valor real)\n",
        "train_residuals = y_train - train_predictions\n",
        "test_residuals = y_test - test_predictions\n",
        "\n",
        "# Gráfico de dispersión para los residuos del conjunto de entrenamiento\n",
        "plt.scatter(train_predictions, train_residuals, label='Train Data', alpha=0.5)\n",
        "plt.hlines(y=0, xmin=train_predictions.min(), xmax=train_predictions.max(), colors='r', linestyles='--')\n",
        "plt.title('Residuals for Training Data')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Gráfico de dispersión para los residuos del conjunto de prueba\n",
        "plt.scatter(test_predictions, test_residuals, label='Test Data', alpha=0.5)\n",
        "plt.hlines(y=0, xmin=test_predictions.min(), xmax=test_predictions.max(), colors='r', linestyles='--')\n",
        "plt.title('Residuals for Test Data')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "twdWgMCh8X0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizar predicciones en el conjunto de prueba\n",
        "test_predictions = ridge_model.predict(X_test).flatten()\n",
        "\n",
        "# Gráfico de dispersión de las etiquetas verdaderas vs predicciones\n",
        "plt.scatter(y_test, test_predictions)\n",
        "\n",
        "# Etiquetas de los ejes\n",
        "plt.xlabel('True Values [charges]')\n",
        "plt.ylabel('Predictions [charges]')\n",
        "\n",
        "# Establecer un aspecto de eje igual y cuadrado para la gráfica\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "\n",
        "# Establecer los límites de los ejes para tener el mismo rango\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "\n",
        "# Dibujar una línea y=x para referencia\n",
        "plt.plot([-100, 100], [-100, 100])\n",
        "\n",
        "# Ajustar un modelo lineal a los datos para obtener la línea de tendencia\n",
        "z = np.polyfit(y_test, test_predictions, 1)\n",
        "p = np.poly1d(z)\n",
        "\n",
        "# Dibujar la línea de tendencia\n",
        "plt.plot(y_test, p(y_test), \"r--\")\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0Hn6qTUvChxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el error de predicción\n",
        "error = test_predictions- y_test\n",
        "\n",
        "# Crear el histograma de los errores de predicción\n",
        "plt.hist(error, bins=25)\n",
        "plt.xlabel(\"Prediction Error [charges]\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bkyBpTCWDK65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# errors_nn es un array de los errores de predicción de la red neuronal\n",
        "# errors_lr es un array de los errores de predicción de la regresión lineal\n",
        "errors_nn = improved_model.predict(normed_test_data).flatten() - test_labels\n",
        "errors_lr = ridge_model.predict(X_test).flatten() - y_test\n",
        "\n",
        "# Convertir a valores absolutos\n",
        "errors_nn_abs = np.abs(errors_nn)\n",
        "errors_lr_abs = np.abs(errors_lr)\n",
        "\n",
        "# Crear una estructura de datos adecuada para el boxplot\n",
        "data_to_plot = [errors_nn_abs, errors_lr_abs]\n",
        "labels = ['Neural Network', 'Linear Regression']\n",
        "\n",
        "# Crear el boxplot\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.boxplot(data=data_to_plot)\n",
        "plt.xticks(range(len(labels)), labels)\n",
        "plt.ylabel('Absolute Prediction Error [charges]')\n",
        "plt.title('Comparison of Prediction Errors between Models')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ilhH0HnSFJl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apartado B"
      ],
      "metadata": {
        "id": "nmvtgSa1H_sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descripción del Conjunto de Datos y Problema de Clasificación\n",
        "\n",
        "## Contexto del Conjunto de Datos\n",
        "\n",
        "El conjunto de datos utilizado se enfoca en los clientes de un servicio de tarjetas de crédito de un banco. Contiene información detallada de 10,000 clientes, incluyendo características como edad, salario, estado civil, límite de crédito y categoría de la tarjeta de crédito. Una característica destacada es el nivel educativo de los clientes, el cual se presenta en distintas categorías.\n",
        "\n",
        "## Características del Conjunto de Datos\n",
        "\n",
        "- **Número de Observaciones**: 10,000\n",
        "- **Número de Características**: Aproximadamente 18\n",
        "- **Variables Clave**:\n",
        "  - **Nivel Educativo**: Categoría principal de interés.\n",
        "  - **Datos Demográficos**: Edad, estado civil.\n",
        "  - **Datos Financieros**: Salario, límite de crédito.\n",
        "  - **Uso de la Tarjeta de Crédito**: Categoría de la tarjeta, etc.\n",
        "\n",
        "## Problema de Clasificación\n",
        "\n",
        "### Objetivo\n",
        "\n",
        "El objetivo principal es clasificar a los clientes en categorías de nivel educativo. El nivel educativo es una variable categórica que podría tener clases como \"Secundaria\", \"Universitaria\", \"Postgrado\", etc.\n",
        "\n",
        "### Importancia\n",
        "\n",
        "Comprender la distribución del nivel educativo entre los clientes puede ayudar al banco a ofrecer productos más personalizados y mejorar su estrategia de marketing.\n",
        "\n",
        "### Desafíos\n",
        "\n",
        "- **Equilibrio de Clases**: Si algunas categorías educativas son mucho menos comunes que otras, esto podría presentar un desafío en términos de balanceo de clases.\n",
        "- **Relaciones No Lineales**: Las relaciones entre el nivel educativo y otras características podrían no ser lineales o podrían ser influenciadas por factores ocultos.\n",
        "\n",
        "### Métodos Propuestos\n",
        "\n",
        "- **Análisis Exploratorio de Datos**: Para entender la distribución de las distintas características, especialmente el nivel educativo.\n",
        "- **Modelos de Clasificación Multinomial**: Dado que el objetivo es clasificar cada observación en una de varias categorías de nivel educativo, los modelos como Regresión Logística Multinomial, Árboles de Decisión o Random Forest pueden ser adecuados.\n",
        "- **Validación Cruzada**: Para evaluar la eficacia de los modelos y asegurar que funcionen bien en datos no vistos.\n",
        "- **Técnicas de Balanceo de Clases**: En caso de desequilibrio en las clases, se podrían usar técnicas como SMOTE para equilibrar las categorías del nivel educativo.\n",
        "\n",
        "El enfoque en el nivel educativo y su relación con otras variables proporciona una oportunidad valiosa para entender mejor la base de clientes del banco y mejorar la toma de decisiones basada en datos.\n"
      ],
      "metadata": {
        "id": "xK6xKMVWSv0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaciones de bibliotecas estándar\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Importaciones de sklearn para preprocesamiento y evaluación de modelos\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Importaciones de imblearn para manejo de desbalance en los datos\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Importaciones de keras para construcción y entrenamiento de modelos de deep learning\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "fX6j7HiosP1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos\n",
        "url = \"https://raw.githubusercontent.com/bonillahermes/Datasets/main/BankChurners.csv\"\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "7RZYufJ4QSUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "nLA7BSN2QzlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "5tEVxl8iREhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrando el conjunto de datos para omitir las categorías 'Unknown' en 'Marital_Status' y 'Education_Level'\n",
        "df= df[(df['Marital_Status'] != 'Unknown') & (df['Education_Level'] != 'Unknown')]\n",
        "\n",
        "# Mostrando las primeras filas del conjunto de datos filtrado para verificar\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sroTfhXTTOmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminando las columnas especificadas del dataframe df\n",
        "columns_to_drop = ['CLIENTNUM',\n",
        "                   'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
        "                   'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2']\n",
        "\n",
        "df = df.drop(columns=columns_to_drop)\n",
        "\n",
        "# Mostrando las primeras filas del dataframe modificado para verificar\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JD1aTyDDVGqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo de Clasificación No Basado en Redes Neuronales"
      ],
      "metadata": {
        "id": "PdSugvzpXBLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificar las variables categóricas\n",
        "le = LabelEncoder()\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == object:\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "\n",
        "# Dividiendo el conjunto de datos\n",
        "X = df.drop('Education_Level', axis=1)  # Características\n",
        "y = df['Education_Level']  # Variable objetivo\n",
        "\n",
        "# Dividir en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Aplicar SMOTE solo al conjunto de entrenamiento\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "CEofxNUfg1kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo de Random Forest con los mejores hiperparámetros encontrados\n",
        "best_rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    max_depth=None,\n",
        "    bootstrap=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Entrenar el modelo con los datos balanceados\n",
        "best_rf.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# Imprimir el informe de clasificación\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n"
      ],
      "metadata": {
        "id": "wGbtLwmHi3YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando las métricas para el modelo de Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
        "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
        "f1_score_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
        "\n",
        "print(accuracy_rf)\n",
        "print(precision_rf)\n",
        "print(recall_rf)\n",
        "print(f1_score_rf)\n",
        "\n",
        "# Creando listas de métricas (solo Random Forest en este caso)\n",
        "metrics_rf = [accuracy_rf, precision_rf, recall_rf, f1_score_rf]\n",
        "labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "# Graficando las métricas\n",
        "x = range(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects = ax.bar(x, metrics_rf, width, label='Random Forest')\n",
        "\n",
        "# Añadiendo títulos y etiquetas\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Métricas del Modelo de Random Forest')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WeGw75trZfLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Clasificación de Red Neuronal Usandos Keras"
      ],
      "metadata": {
        "id": "ElXgCU06XlsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalización de las características\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Dividiendo el conjunto de datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Construyendo el modelo de red neuronal mejorado\n",
        "model_nn = Sequential()\n",
        "model_nn.add(Dense(128, input_dim=X_train.shape[1]))\n",
        "model_nn.add(BatchNormalization())\n",
        "model_nn.add(Activation('relu'))\n",
        "model_nn.add(Dropout(0.5))\n",
        "model_nn.add(Dense(64))\n",
        "model_nn.add(BatchNormalization())\n",
        "model_nn.add(Activation('relu'))\n",
        "model_nn.add(Dropout(0.5))\n",
        "model_nn.add(Dense(y.nunique(), activation='softmax'))  # Número de clases en y\n",
        "\n",
        "# Compilando el modelo con un optimizador Adam ajustado\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model_nn.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "# Entrenando el modelo con callbacks\n",
        "model_nn.fit(X_train, y_train, epochs=1000, batch_size=32, validation_split=0.2, callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Cargar el mejor modelo guardado y evaluar en el conjunto de prueba\n",
        "model_nn.load_weights('best_model.h5')\n",
        "_, accuracy = model_nn.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "id": "BDq0QZ4-Xt43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacer predicciones\n",
        "y_pred_nn = model_nn.predict(X_test)\n",
        "y_pred_nn = y_pred_nn.argmax(axis=1)  # Convertir predicciones de probabilidades a etiquetas"
      ],
      "metadata": {
        "id": "_j2cr6ticRrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular métricas\n",
        "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
        "precision_nn = precision_score(y_test, y_pred_nn, average='weighted')\n",
        "recall_nn = recall_score(y_test, y_pred_nn, average='weighted')\n",
        "f1_score_nn = f1_score(y_test, y_pred_nn, average='weighted')"
      ],
      "metadata": {
        "id": "9bqt5_yXEGdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creando listas de métricas para el modelo de red neuronal\n",
        "metrics_nn = [accuracy_nn, precision_nn, recall_nn, f1_score_nn]\n",
        "labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "# Graficando las métricas del modelo de red neuronal\n",
        "x = range(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "rects = ax.bar(x, metrics_nn, width, label='Red Neuronal')\n",
        "\n",
        "# Añadiendo títulos y etiquetas\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Métricas del Modelo de Red Neuronal')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "brD1M2nVcTkw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}